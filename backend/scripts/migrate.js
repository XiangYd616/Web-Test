/**
 * æ•°æ®åº“è¿ç§»ç®¡ç†è„šæœ¬
 * æ”¯æŒæ•°æ®åº“ç‰ˆæœ¬ç®¡ç†ã€è¿ç§»ã€å›æ»šã€å¤‡ä»½ç­‰åŠŸèƒ½
 */

const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

// æ•°æ®åº“é…ç½®
const dbConfig = {
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT) || 5432,
  database: process.env.DB_NAME || 'testweb_dev',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || 'postgres',
};

// è¿ç§»æ–‡ä»¶ç›®å½•
const MIGRATIONS_DIR = path.join(__dirname, '../migrations');
const BACKUPS_DIR = path.join(__dirname, '../backups');

// ç¡®ä¿ç›®å½•å­˜åœ¨
[MIGRATIONS_DIR, BACKUPS_DIR].forEach(dir => {
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }
});

/**
 * æ•°æ®åº“è¿ç§»ç®¡ç†å™¨
 */
class DatabaseMigrator {
  constructor() {
    this.pool = new Pool(dbConfig);
  }

  /**
   * åˆå§‹åŒ–è¿ç§»è¡¨
   */
  async initMigrationTable() {
    const client = await this.pool.connect();
    try {
      await client.query(`
        CREATE TABLE IF NOT EXISTS schema_migrations (
          id SERIAL PRIMARY KEY,
          version VARCHAR(255) UNIQUE NOT NULL,
          name VARCHAR(255) NOT NULL,
          executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          execution_time INTEGER,
          checksum VARCHAR(255)
        )
      `);
      console.log('âœ… è¿ç§»è¡¨åˆå§‹åŒ–å®Œæˆ');
    } finally {
      client.release();
    }
  }

  /**
   * è·å–å·²æ‰§è¡Œçš„è¿ç§»
   */
  async getExecutedMigrations() {
    const client = await this.pool.connect();
    try {
      const result = await client.query(
        'SELECT version FROM schema_migrations ORDER BY version'
      );
      return result.rows.map(row => row.version);
    } finally {
      client.release();
    }
  }

  /**
   * è·å–å¾…æ‰§è¡Œçš„è¿ç§»æ–‡ä»¶
   */
  async getPendingMigrations() {
    const executedMigrations = await this.getExecutedMigrations();
    const migrationFiles = fs.readdirSync(MIGRATIONS_DIR)
      .filter(file => file.endsWith('.sql'))
      .sort();

    return migrationFiles.filter(file => {
      const version = file.replace('.sql', '');
      return !executedMigrations.includes(version);
    });
  }

  /**
   * æ‰§è¡Œå•ä¸ªè¿ç§»
   */
  async executeMigration(filename) {
    const version = filename.replace('.sql', '');
    const filePath = path.join(MIGRATIONS_DIR, filename);
    const sql = fs.readFileSync(filePath, 'utf8');
    
    const client = await this.pool.connect();
    const startTime = Date.now();
    
    try {
      await client.query('BEGIN');
      
      // æ‰§è¡Œè¿ç§»SQL
      await client.query(sql);
      
      // è®°å½•è¿ç§»
      const executionTime = Date.now() - startTime;
      const checksum = require('crypto').createHash('md5').update(sql).digest('hex');
      
      await client.query(
        'INSERT INTO schema_migrations (version, name, execution_time, checksum) VALUES ($1, $2, $3, $4)',
        [version, filename, executionTime, checksum]
      );
      
      await client.query('COMMIT');
      console.log(`âœ… è¿ç§» ${filename} æ‰§è¡ŒæˆåŠŸ (${executionTime}ms)`);
      
    } catch (error) {
      await client.query('ROLLBACK');
      console.error(`âŒ è¿ç§» ${filename} æ‰§è¡Œå¤±è´¥:`, error.message);
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * æ‰§è¡Œæ‰€æœ‰å¾…æ‰§è¡Œçš„è¿ç§»
   */
  async migrate() {
    
    await this.initMigrationTable();
    const pendingMigrations = await this.getPendingMigrations();
    
    if (pendingMigrations.length === 0) {
      return;
    }
    
    pendingMigrations.forEach(file => );
    
    for (const migration of pendingMigrations) {
      await this.executeMigration(migration);
    }
    
  }

  /**
   * æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
   */
  async checkStatus() {
    console.log('ğŸ” æ£€æŸ¥æ•°æ®åº“çŠ¶æ€...');
    
    try {
      await this.initMigrationTable();
      
      const executedMigrations = await this.getExecutedMigrations();
      const pendingMigrations = await this.getPendingMigrations();
      
      
      if (executedMigrations.length > 0) {
        executedMigrations.forEach(version => );
      }
      
      if (pendingMigrations.length > 0) {
        pendingMigrations.forEach(file => );
      }
      
    } catch (error) {
      console.error('âŒ æ£€æŸ¥æ•°æ®åº“çŠ¶æ€å¤±è´¥:', error.message);
    }
  }

  /**
   * åˆ›å»ºæ•°æ®åº“å¤‡ä»½
   */
  async backup() {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const backupFile = path.join(BACKUPS_DIR, `backup-${timestamp}.sql`);
    
    
    try {
      const command = `pg_dump -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.user} -d ${dbConfig.database} -f ${backupFile}`;
      
      // è®¾ç½®å¯†ç ç¯å¢ƒå˜é‡
      const env = { ...process.env, PGPASSWORD: dbConfig.password };
      
      execSync(command, { env, stdio: 'inherit' });
      
      console.log(`âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ: ${backupFile}`);
      return backupFile;
      
    } catch (error) {
      console.error('âŒ åˆ›å»ºå¤‡ä»½å¤±è´¥:', error.message);
      throw error;
    }
  }

  /**
   * ç”Ÿæˆæ–°çš„è¿ç§»æ–‡ä»¶
   */
  generateMigration(name) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').replace('T', '_').substring(0, 19);
    const filename = `${timestamp}_${name.replace(/\s+/g, '_').toLowerCase()}.sql`;
    const filePath = path.join(MIGRATIONS_DIR, filename);
    
    const template = `-- Migration: ${name}
-- Created: ${new Date().toISOString()}
-- Description: ${name}

-- Up migration
BEGIN;

-- Add your migration SQL here
-- Example:
-- CREATE TABLE example (
--   id SERIAL PRIMARY KEY,
--   name VARCHAR(255) NOT NULL,
--   created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
-- );

COMMIT;

-- Down migration (for rollback - not implemented yet)
-- BEGIN;
-- DROP TABLE IF EXISTS example;
-- COMMIT;
`;
    
    fs.writeFileSync(filePath, template);
    console.log(`âœ… è¿ç§»æ–‡ä»¶åˆ›å»ºæˆåŠŸ: ${filename}`);
    
    return filePath;
  }

  /**
   * å…³é—­è¿æ¥æ± 
   */
  async close() {
    await this.pool.end();
  }
}

/**
 * å‘½ä»¤è¡Œæ¥å£
 */
async function main() {
  const command = process.argv[2];
  const migrator = new DatabaseMigrator();
  
  try {
    switch (command) {
      case 'migrate':
        await migrator.migrate();
        break;
        
      case 'check':
      case 'status':
        await migrator.checkStatus();
        break;
        
      case 'backup':
        await migrator.backup();
        break;
        
      case 'generate':
        const name = process.argv[3];
        if (!name) {
          console.error('âŒ è¯·æä¾›è¿ç§»åç§°: npm run db:generate "migration name"');
          process.exit(1);
        }
        migrator.generateMigration(name);
        break;
        
      default:
ğŸ—„ï¸  æ•°æ®åº“è¿ç§»å·¥å…·

ä½¿ç”¨æ–¹æ³•:
  npm run db:migrate     - æ‰§è¡Œæ‰€æœ‰å¾…æ‰§è¡Œçš„è¿ç§»
  npm run db:check       - æ£€æŸ¥æ•°æ®åº“è¿ç§»çŠ¶æ€
  npm run db:backup      - åˆ›å»ºæ•°æ®åº“å¤‡ä»½
  npm run db:generate    - ç”Ÿæˆæ–°çš„è¿ç§»æ–‡ä»¶

ç¤ºä¾‹:
  npm run db:generate "add user table"
  npm run db:migrate
  npm run db:check
        `);
        break;
    }
  } catch (error) {
    console.error('âŒ æ“ä½œå¤±è´¥:', error.message);
    process.exit(1);
  } finally {
    await migrator.close();
  }
}

// è¿è¡Œå‘½ä»¤è¡Œæ¥å£
if (require.main === module) {
  main().catch(console.error);
}

module.exports = { DatabaseMigrator };
